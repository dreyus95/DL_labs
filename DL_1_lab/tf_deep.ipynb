{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import  ListedColormap\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 10\n",
    "CLASSES = 3\n",
    "DISTRIBUTIONS = 6\n",
    "SEED = 106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TFDeep:\n",
    "    \"\"\"\n",
    "        Class that represents a deep neural network implementation in tensorflow.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shapes, param_delta=0.1, param_lambda=0.01):\n",
    "        \"\"\"Arguments:\n",
    "           - D: dimensions of each datapoint\n",
    "           - C: number of classes\n",
    "           - param_delta: training step\n",
    "        \"\"\"\n",
    "        self.X = tf.placeholder(dtype=tf.float32, shape=[None, shapes[0]])\n",
    "        self.Yoh_ = tf.placeholder(dtype=tf.float32, shape=[None, shapes[-1]])\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.hs = []\n",
    "\n",
    "        for index, shape in enumerate(shapes[1:]):\n",
    "            self.weights.append(tf.Variable(initial_value=tf.random_normal([shapes[index], shape])))\n",
    "            self.biases.append(tf.Variable(initial_value=tf.random_normal([1, shape])))\n",
    "\n",
    "        # NN input\n",
    "        # self.hs.append(tf.nn.sigmoid(tf.matmul(self.X, self.weights[0]) + self.biases[0]))\n",
    "        self.hs.append(tf.nn.relu(tf.matmul(self.X, self.weights[0]) + self.biases[0]))\n",
    "\n",
    "        # NN inner connections\n",
    "        for i in range(1, len(shapes[1:-1])):\n",
    "            self.hs.append(tf.nn.relu(tf.matmul(self.hs[-1], self.weights[i]) + self.biases[i]))\n",
    "            # self.hs.append(tf.nn.sigmoid(tf.matmul(self.hs[-1], self.weights[i]) + self.biases[i]))\n",
    "\n",
    "        # NN output\n",
    "        if len(shapes[1:-1]) == 0:\n",
    "            # regular logistic regression\n",
    "            output = tf.matmul(self.X, self.weights[-1]) + self.biases[-1]\n",
    "        else:\n",
    "            # neural network last layer output\n",
    "            output = tf.matmul(self.hs[-1], self.weights[-1]) + self.biases[-1]\n",
    "\n",
    "        self.probs = tf.nn.softmax(output)\n",
    "\n",
    "        self.cross_entropy = tf.reduce_mean(-tf.reduce_sum(self.Yoh_ * tf.log(self.probs + 1e-8), axis=1))\n",
    "        self.regularization = [param_lambda * tf.nn.l2_loss(weights) for weights in self.weights]\n",
    "        self.loss = self.cross_entropy + tf.add_n(self.regularization)\n",
    "\n",
    "        self.train_step = tf.train.GradientDescentOptimizer(param_delta).minimize(self.loss)\n",
    "\n",
    "        self.session = tf.InteractiveSession()\n",
    "\n",
    "    def train(self, X, Yoh_, param_niter):\n",
    "        \"\"\"Arguments:\n",
    "           - X: actual datapoints [NxD]\n",
    "           - Yoh_: one-hot encoded labels [NxC]\n",
    "           - param_niter: number of iterations\n",
    "        \"\"\"\n",
    "        self.session.run(tf.initialize_all_variables())\n",
    "\n",
    "        for i in range(param_niter+1):\n",
    "            tr = self.session.run([self.train_step], feed_dict={self.X: X, self.Yoh_: Yoh_})\n",
    "            if i % 1000 == 0:\n",
    "                loss = self.session.run(self.loss, feed_dict={self.X: X, self.Yoh_: Yoh_})\n",
    "                print(\"{0:4}. Loss: {1:.8f}\".format(i, loss))\n",
    "\n",
    "    def eval(self, X):\n",
    "        \"\"\"Arguments:\n",
    "           - X: actual datapoints [NxD]\n",
    "           Returns: predicted class probabilites [NxC]\n",
    "        \"\"\"\n",
    "        probs = self.session.run(self.probs, feed_dict={self.X: X})\n",
    "        return probs\n",
    "\n",
    "    def classify(self, X):\n",
    "        return np.argmax(self.eval(X), axis=1)\n",
    "\n",
    "    def eval_perf(self, Y, Y_):\n",
    "        # needed to compute scores of our model\n",
    "        # 'weighted' takes into consideration labels imbalance\n",
    "        if max(int(max(Y_) + 1), int(max(Y) + 1)) == 2:\n",
    "            average = 'binary'\n",
    "        else:\n",
    "            average = 'weighted'\n",
    "\n",
    "        accuracy = accuracy_score(Y_, Y)\n",
    "        precision = precision_score(Y_, Y, average=average)\n",
    "        recall = recall_score(Y_, Y, average=average)\n",
    "        f1 = f1_score(Y_, Y, average=average)\n",
    "\n",
    "        print(\"Accuracy: {0:.3f}\\n\"\n",
    "              \"Precision: {1:.3f}\\n\"\n",
    "              \"Recall: {2:.3f}\\n\"\n",
    "              \"F1: {3:.3f} \".format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "X, Y_ = data.sample_gmm_2d(DISTRIBUTIONS, CLASSES, NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Yoh_ = Y_.reshape(-1)\n",
    "Yoh_ = np.eye(CLASSES)[Yoh_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shape = [2, 10, 15,CLASSES]\n",
    "\n",
    "tfdeep = TFDeep(shape, param_delta=0.01, param_lambda=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tfdeep.train(X, Yoh_, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs = tfdeep.eval(X)\n",
    "print(\"Predicted:\\n\", np.argmax(probs, axis=1))\n",
    "print(\"True:\\n\",Y_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfdeep.eval_perf(np.argmax(probs, axis=1), np.argmax(Yoh_, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = ['red', 'green', 'blue']\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y_.flatten(), cmap=ListedColormap(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.plot_decision_boundary(X, lambda x: tfdeep.classify(x))\n",
    "# graph the data points\n",
    "data.graph_data(X, Y_, np.argmax(probs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEED = 105\n",
    "np.random.seed(SEED)\n",
    "tf.set_random_seed(SEED)\n",
    "X2, Y_2 = data.sample_gmm_2d(DISTRIBUTIONS, CLASSES, NUM_EXAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Yoh_2 = Y_2.reshape(-1)\n",
    "Yoh_2 = np.eye(CLASSES)[Yoh_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfdeep2 = TFDeep(shape, param_delta=0.03, param_lambda=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfdeep2.train(X2, Yoh_2, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs2 = tfdeep2.eval(X2)\n",
    "print(\"Predicted:\\n\", np.argmax(probs2, axis=1))\n",
    "print(\"True:\\n\",Y_2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfdeep2.eval_perf(np.argmax(probs2, axis=1), np.argmax(Yoh_2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X2[:, 0], X2[:, 1], c=Y_2.flatten(), cmap=ListedColormap(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.plot_decision_boundary(X2, lambda x: tfdeep2.classify(x))\n",
    "# graph the data points\n",
    "data.graph_data(X2, Y_2, np.argmax(probs2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
